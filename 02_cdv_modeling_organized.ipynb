{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd7694b",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup\n",
    "\n",
    "Import all necessary libraries and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "942e3fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Guy\\anaconda3\\envs\\ICPM_paper2025_2nd_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# RealCause imports\n",
    "from data.sepsis import load_sepsis\n",
    "from utils import to_data_format\n",
    "\n",
    "# CDV utilities\n",
    "from cdv_utils.generator_validation import (\n",
    "    train_multiple_models, analyze_model_performance, select_best_model,\n",
    "    validate_generator_quality, generate_synthetic_data, create_dataframe_from_synthetic_data\n",
    ")\n",
    "from cdv_utils.causal_modeling import (\n",
    "    assign_variants_by_patterns, group_by_variants_with_filtered_columns,\n",
    "    process_test_data_with_training_variants\n",
    ")\n",
    "from cdv_utils.experiment_runner import (\n",
    "    run_multi_seed_experiment, analyze_experiment_results\n",
    ")\n",
    "\n",
    "# Global constants\n",
    "INITIAL_SEED = 420\n",
    "EXPERIMENT_SEED = 42\n",
    "R2_THRESHOLD = 0.1\n",
    "NUM_VARIANTS = 3\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f15ad7",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration\n",
    "\n",
    "Load the sepsis dataset and examine its basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef810563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sepsis dataset...\n",
      "Loading sepsis dataset from datasets\\sepsis_cases.csv\n",
      "\n",
      "Dataset dimensions:\n",
      "- Covariates (w): (810, 30)\n",
      "- Treatment (t): (810,)\n",
      "- Outcome (y): (810,)\n",
      "\n",
      "Treatment distribution:\n",
      "- Treatment (1): 72 (8.89%)\n",
      "- Control (0): 738 (91.11%)\n",
      "\n",
      "Outcome statistics:\n",
      "- Min: 280.0, Max: 55704.0\n",
      "- Mean: 7457.6469, Std: 6749.6825\n"
     ]
    }
   ],
   "source": [
    "# Load the sepsis dataset\n",
    "print(\"Loading sepsis dataset...\")\n",
    "sepsis_data = load_sepsis(data_format='numpy', dataroot=\"datasets\")\n",
    "\n",
    "# Extract data components\n",
    "if isinstance(sepsis_data, tuple):\n",
    "    w, t, y = sepsis_data\n",
    "else:\n",
    "    w, t, y = sepsis_data[\"w\"], sepsis_data[\"t\"], sepsis_data[\"y\"]\n",
    "\n",
    "# Display basic dataset statistics\n",
    "print(f\"\\nDataset dimensions:\")\n",
    "print(f\"- Covariates (w): {w.shape}\")\n",
    "print(f\"- Treatment (t): {t.shape}\")\n",
    "print(f\"- Outcome (y): {y.shape}\")\n",
    "\n",
    "print(f\"\\nTreatment distribution:\")\n",
    "print(f\"- Treatment (1): {np.sum(t == 1)} ({np.mean(t == 1)*100:.2f}%)\")\n",
    "print(f\"- Control (0): {np.sum(t == 0)} ({np.mean(t == 0)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nOutcome statistics:\")\n",
    "print(f\"- Min: {y.min()}, Max: {y.max()}\")\n",
    "print(f\"- Mean: {y.mean():.4f}, Std: {y.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4270086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns (30):\n",
      "   1. InfectionSuspected\n",
      "   2. DiagnosticBlood\n",
      "   3. DisfuncOrg\n",
      "   4. SIRSCritTachypnea\n",
      "   5. Hypotensie\n",
      "   6. SIRSCritHeartRate\n",
      "   7. Infusion\n",
      "   8. DiagnosticArtAstrup\n",
      "   9. Age\n",
      "  10. DiagnosticIC\n",
      "  11. DiagnosticSputum\n",
      "  12. DiagnosticLiquor\n",
      "  13. DiagnosticOther\n",
      "  14. SIRSCriteria2OrMore\n",
      "  15. DiagnosticXthorax\n",
      "  16. SIRSCritTemperature\n",
      "  17. DiagnosticUrinaryCulture\n",
      "  18. SIRSCritLeucos\n",
      "  19. Oligurie\n",
      "  20. DiagnosticLacticAcid\n",
      "  21. Hypoxie\n",
      "  22. DiagnosticUrinarySediment\n",
      "  23. DiagnosticECG\n",
      "  24. Leucocytes\n",
      "  25. CRP\n",
      "  26. LacticAcid\n",
      "  27. Leucocytes_2\n",
      "  28. CRP_2\n",
      "  29. LacticAcid_2\n",
      "  30. LacticAcid_3\n",
      "\n",
      "Dataset ready for RealCause modeling!\n"
     ]
    }
   ],
   "source": [
    "# Load original CSV to get feature names\n",
    "original_sepsis_df = pd.read_csv(os.path.join(\"datasets\", \"sepsis_cases.csv\"))\n",
    "w_cols = [col for col in original_sepsis_df.columns if col not in ['t', 'y', 'y0', 'y1', 'ite', 'variant']]\n",
    "\n",
    "print(f\"Feature columns ({len(w_cols)}):\")\n",
    "for i, col in enumerate(w_cols):\n",
    "    print(f\"  {i+1:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nDataset ready for RealCause modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e5f9e7",
   "metadata": {},
   "source": [
    "## 3. RealCause Generator Training and Validation\n",
    "\n",
    "Train RealCause models to generate synthetic data and validate their quality through statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239a5c6",
   "metadata": {},
   "source": [
    "### 3.1 Train RealCause Models\n",
    "\n",
    "Train multiple RealCause models with different architectures and seeds to find the best generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6d777b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RealCause models...\n",
      "- Save directory: save/sepsis_model_organized\n",
      "- Training seeds: [420]\n",
      "\n",
      "Training medium architecture:\n",
      "- Hidden layers: 3\n",
      "- Hidden units: 128\n",
      "- Activation: ReLU\n",
      "n_train: 405\tn_val: 81\tn_test: 324\n",
      "test_idxs:  (324,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 valid loss 2.418264389038086\n",
      "saving best-val-loss model\n",
      "Iteration 20 valid loss 2.4024510383605957\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/400 [00:00<00:33, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 30 valid loss 2.385331630706787\n",
      "saving best-val-loss model\n",
      "Iteration 40 valid loss 2.3649020195007324\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/400 [00:00<00:37, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 50 valid loss 2.337759494781494\n",
      "saving best-val-loss model\n",
      "Iteration 60 valid loss 2.2941064834594727\n",
      "saving best-val-loss model\n",
      "Iteration 70 valid loss 2.2091927528381348\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/400 [00:00<00:34, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 80 valid loss 2.0332934856414795\n",
      "saving best-val-loss model\n",
      "Iteration 90 valid loss 1.7028712034225464\n",
      "saving best-val-loss model\n",
      "Iteration 100: 0.4672797918319702 0.6980330348014832\n",
      "Iteration 100 valid loss 1.2539522647857666\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 10/400 [00:02<01:32,  4.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 110 valid loss 0.8000217080116272\n",
      "saving best-val-loss model\n",
      "Iteration 120 valid loss 0.5763252973556519\n",
      "saving best-val-loss model\n",
      "Iteration 130 valid loss 0.5382680892944336\n",
      "saving best-val-loss model\n",
      "Iteration 140 valid loss 0.5182644724845886\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 12/400 [00:02<01:11,  5.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 150 valid loss 0.42871400713920593\n",
      "saving best-val-loss model\n",
      "Iteration 160 valid loss 0.39263656735420227\n",
      "saving best-val-loss model\n",
      "Iteration 170 valid loss 0.38397377729415894\n",
      "saving best-val-loss model\n",
      "Iteration 180 valid loss 0.3025500774383545\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 14/400 [00:02<00:58,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 190 valid loss 0.32862409949302673\n",
      "Iteration 200: 0.1035914421081543 -0.7852538228034973\n",
      "Iteration 200 valid loss 0.242898628115654\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 18/400 [00:03<01:36,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 210 valid loss 0.26330703496932983\n",
      "Iteration 220 valid loss 0.21923796832561493\n",
      "saving best-val-loss model\n",
      "Iteration 230 valid loss 0.17390188574790955\n",
      "saving best-val-loss model\n",
      "Iteration 240 valid loss 0.1874932050704956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 20/400 [00:04<01:16,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 250 valid loss 0.13213075697422028\n",
      "saving best-val-loss model\n",
      "Iteration 260 valid loss 0.125044584274292\n",
      "saving best-val-loss model\n",
      "Iteration 270 valid loss 0.10178057104349136\n",
      "saving best-val-loss model\n",
      "Iteration 280 valid loss 0.09531953930854797\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 22/400 [00:04<01:02,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 290 valid loss 0.026253821328282356\n",
      "saving best-val-loss model\n",
      "Iteration 300: 0.13745781779289246 -0.6536674499511719\n",
      "Iteration 300 valid loss 0.006642424035817385\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 26/400 [00:06<01:39,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 310 valid loss 0.012217682786285877\n",
      "Iteration 320 valid loss -0.011399018578231335\n",
      "saving best-val-loss model\n",
      "Iteration 330 valid loss -0.04794143885374069\n",
      "saving best-val-loss model\n",
      "Iteration 340 valid loss -0.009733912535011768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 28/400 [00:06<01:18,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 350 valid loss -0.08216757327318192\n",
      "saving best-val-loss model\n",
      "Iteration 360 valid loss -0.09998639672994614\n",
      "saving best-val-loss model\n",
      "Iteration 370 valid loss -0.10957968980073929\n",
      "saving best-val-loss model\n",
      "Iteration 380 valid loss -0.12799076735973358\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 30/400 [00:06<01:03,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 390 valid loss -0.1634788066148758\n",
      "saving best-val-loss model\n",
      "Iteration 400: 0.3281521797180176 -1.1229832172393799\n",
      "Iteration 400 valid loss -0.07467498630285263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 32/400 [00:07<02:11,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 410 valid loss -0.2114182859659195\n",
      "saving best-val-loss model\n",
      "Iteration 420 valid loss -0.2398660033941269\n",
      "saving best-val-loss model\n",
      "Iteration 430 valid loss -0.19375693798065186\n",
      "Iteration 440 valid loss -0.15508055686950684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 36/400 [00:08<01:18,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 450 valid loss -0.2956303358078003\n",
      "saving best-val-loss model\n",
      "Iteration 460 valid loss -0.24003130197525024\n",
      "Iteration 470 valid loss -0.1650496870279312\n",
      "Iteration 480 valid loss -0.30415791273117065\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 38/400 [00:08<01:03,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 490 valid loss -0.23288977146148682\n",
      "Iteration 500: 0.27330371737480164 -1.0643068552017212\n",
      "Iteration 500 valid loss -0.3084053099155426\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 40/400 [00:10<02:13,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 510 valid loss -0.32396745681762695\n",
      "saving best-val-loss model\n",
      "Iteration 520 valid loss -0.329973042011261\n",
      "saving best-val-loss model\n",
      "Iteration 530 valid loss -0.3776317536830902\n",
      "saving best-val-loss model\n",
      "Iteration 540 valid loss -0.34051036834716797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 44/400 [00:10<01:19,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 550 valid loss -0.36173558235168457\n",
      "Iteration 560 valid loss -0.29664865136146545\n",
      "Iteration 570 valid loss -0.4069206416606903\n",
      "saving best-val-loss model\n",
      "Iteration 580 valid loss -0.3975522220134735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 46/400 [00:10<01:04,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 590 valid loss -0.425622820854187\n",
      "saving best-val-loss model\n",
      "Iteration 600: 0.11924449354410172 -1.120609164237976\n",
      "Iteration 600 valid loss -0.3434846103191376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 48/400 [00:12<02:15,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 610 valid loss -0.4561486840248108\n",
      "saving best-val-loss model\n",
      "Iteration 620 valid loss -0.36341768503189087\n",
      "Iteration 630 valid loss -0.46329817175865173\n",
      "saving best-val-loss model\n",
      "Iteration 640 valid loss -0.43988046050071716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 51/400 [00:12<01:31,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 650 valid loss -0.355774462223053\n",
      "Iteration 660 valid loss -0.4682854115962982\n",
      "saving best-val-loss model\n",
      "Iteration 670 valid loss -0.34872791171073914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 53/400 [00:12<01:11,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 680 valid loss -0.4646718502044678\n",
      "Iteration 690 valid loss -0.4214101731777191\n",
      "Iteration 700: 0.26255449652671814 -1.2625060081481934\n",
      "Iteration 700 valid loss -0.45774027705192566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 56/400 [00:14<02:06,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 710 valid loss -0.4243975877761841\n",
      "Iteration 720 valid loss -0.4216974377632141\n",
      "Iteration 730 valid loss -0.4537234306335449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 58/400 [00:14<01:28,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 740 valid loss -0.4066462516784668\n",
      "Iteration 750 valid loss -0.46501827239990234\n",
      "Iteration 760 valid loss -0.3992795944213867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 60/400 [00:15<01:04,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 770 valid loss -0.5248571038246155\n",
      "saving best-val-loss model\n",
      "Iteration 780 valid loss -0.4847671091556549\n",
      "Iteration 790 valid loss -0.45856794714927673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 61/400 [00:15<00:56,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 800: 0.16983649134635925 -1.256119728088379\n",
      "Iteration 800 valid loss -0.4996081292629242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 64/400 [00:17<02:05,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 810 valid loss -0.49933478236198425\n",
      "Iteration 820 valid loss -0.49181875586509705\n",
      "Iteration 830 valid loss -0.4716547727584839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 66/400 [00:17<01:19,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 840 valid loss -0.5184548497200012\n",
      "Iteration 850 valid loss -0.4438369572162628\n",
      "Iteration 860 valid loss -0.5187420845031738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 67/400 [00:17<01:05,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 870 valid loss -0.47458699345588684\n",
      "Iteration 880 valid loss -0.4896847903728485\n",
      "Iteration 890 valid loss -0.44906672835350037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 69/400 [00:17<00:49,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 900: 0.10869413614273071 -1.1622337102890015\n",
      "Iteration 900 valid loss -0.5329264998435974\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 71/400 [00:19<02:14,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 910 valid loss -0.48261675238609314\n",
      "Iteration 920 valid loss -0.5362051725387573\n",
      "saving best-val-loss model\n",
      "Iteration 930 valid loss -0.47194766998291016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 73/400 [00:19<01:30,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 940 valid loss -0.5055966973304749\n",
      "Iteration 950 valid loss -0.501413106918335\n",
      "Iteration 960 valid loss -0.49938786029815674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 75/400 [00:19<01:08,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 970 valid loss -0.5405816435813904\n",
      "saving best-val-loss model\n",
      "Iteration 980 valid loss -0.4831561744213104\n",
      "Iteration 990 valid loss -0.48429203033447266\n",
      "Iteration 1000: 0.232022225856781 -1.1142841577529907\n",
      "Iteration 1000 valid loss -0.5171507596969604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 79/400 [00:21<01:44,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1010 valid loss -0.4488019645214081\n",
      "Iteration 1020 valid loss -0.4861335754394531\n",
      "Iteration 1030 valid loss -0.5411136746406555\n",
      "saving best-val-loss model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 81/400 [00:21<01:18,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1040 valid loss -0.49512767791748047\n",
      "Iteration 1050 valid loss -0.4977062940597534\n",
      "Iteration 1060 valid loss -0.4828875958919525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 84/400 [00:22<00:52,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1070 valid loss -0.4717780649662018\n",
      "Iteration 1080 valid loss -0.5007752776145935\n",
      "Iteration 1090 valid loss -0.46268871426582336\n",
      "Iteration 1100: 0.05179108306765556 -1.081018328666687\n",
      "Iteration 1100 valid loss -0.44687125086784363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 86/400 [00:23<02:03,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1110 valid loss -0.4381536841392517\n",
      "Iteration 1120 valid loss -0.47629514336586\n",
      "Iteration 1130 valid loss -0.4835464060306549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 88/400 [00:24<01:24,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1140 valid loss -0.405494749546051\n",
      "Iteration 1150 valid loss -0.4636593461036682\n",
      "Iteration 1160 valid loss -0.4765565097332001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 90/400 [00:24<01:04,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1170 valid loss -0.444423109292984\n",
      "Iteration 1180 valid loss -0.46207159757614136\n",
      "Iteration 1190 valid loss -0.4507799446582794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 92/400 [00:24<00:51,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1200: 0.06094418838620186 -1.1036877632141113\n",
      "Iteration 1200 valid loss -0.46245574951171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 94/400 [00:26<01:57,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1210 valid loss -0.4727810025215149\n",
      "Iteration 1220 valid loss -0.44850954413414\n",
      "Iteration 1230 valid loss -0.4483099579811096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 97/400 [00:26<01:09,  4.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1240 valid loss -0.4560627341270447\n",
      "Iteration 1250 valid loss -0.45515796542167664\n",
      "Iteration 1260 valid loss -0.41476157307624817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 99/400 [00:26<00:53,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1270 valid loss -0.45817792415618896\n",
      "Iteration 1280 valid loss -0.3780081570148468\n",
      "Iteration 1290 valid loss -0.42398443818092346\n",
      "Iteration 1300: 0.07119659334421158 -0.956933856010437\n",
      "Iteration 1300 valid loss -0.4241349399089813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 102/400 [00:28<01:42,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1310 valid loss -0.37542617321014404\n",
      "Iteration 1320 valid loss -0.43563276529312134\n",
      "Iteration 1330 valid loss -0.4315357804298401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 104/400 [00:28<01:14,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1340 valid loss -0.35906943678855896\n",
      "Iteration 1350 valid loss -0.4059750735759735\n",
      "Iteration 1360 valid loss -0.37272629141807556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 106/400 [00:29<00:56,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1370 valid loss -0.344805508852005\n",
      "Iteration 1380 valid loss -0.4020414352416992\n",
      "Iteration 1390 valid loss -0.3743710219860077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 107/400 [00:29<00:51,  5.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1400: 0.10957114398479462 -1.1145613193511963\n",
      "Iteration 1400 valid loss -0.33473238348960876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 110/400 [00:31<01:43,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1410 valid loss -0.34178176522254944\n",
      "Iteration 1420 valid loss -0.3590049147605896\n",
      "Iteration 1430 valid loss -0.37137019634246826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 112/400 [00:31<01:15,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1440 valid loss -0.3163614571094513\n",
      "Iteration 1450 valid loss -0.35245081782341003\n",
      "Iteration 1460 valid loss -0.3186449706554413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 114/400 [00:31<00:58,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1470 valid loss -0.32322537899017334\n",
      "Iteration 1480 valid loss -0.30409279465675354\n",
      "Iteration 1490 valid loss -0.3068442642688751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 115/400 [00:31<00:52,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1500: 0.07223530858755112 -1.2168684005737305\n",
      "Iteration 1500 valid loss -0.28760242462158203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 117/400 [00:33<01:20,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1510 valid loss -0.2953440248966217\n",
      "Iteration 1520 valid loss -0.2759971618652344\n",
      "Iteration 1530 valid loss -0.3239732086658478\n",
      "early stopping criterion reached. Ending experiment.\n",
      "loading best-val-loss model (early stopping checkpoint)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model training completed!\n",
      "Trained architectures: ['medium']\n",
      "Models saved to: save/sepsis_model_organized\n"
     ]
    }
   ],
   "source": [
    "# Set up training configuration\n",
    "saveroot = \"save/sepsis_model_organized\"\n",
    "training_seeds = [INITIAL_SEED]  # Can add more seeds: [420, 421, 422]\n",
    "\n",
    "print(\"Training RealCause models...\")\n",
    "print(f\"- Save directory: {saveroot}\")\n",
    "print(f\"- Training seeds: {training_seeds}\")\n",
    "\n",
    "# Train multiple models\n",
    "results, best_model_selector_dict = train_multiple_models(\n",
    "    w, t, y, \n",
    "    w_cols=w_cols,\n",
    "    saveroot=saveroot,\n",
    "    seeds=training_seeds\n",
    ")\n",
    "\n",
    "print(\"\\nModel training completed!\")\n",
    "print(f\"Trained architectures: {list(results.keys())}\")\n",
    "print(f\"Models saved to: {saveroot}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba36b55",
   "metadata": {},
   "source": [
    "### 3.2 Analyze Model Performance\n",
    "\n",
    "Compare the performance of different models using statistical metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a36a933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Architecture</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Univariate: Y KS p-value</th>\n",
       "      <th>Univariate: T KS p-value</th>\n",
       "      <th>Univariate: Y ES p-value</th>\n",
       "      <th>Univariate: T ES p-value</th>\n",
       "      <th>Univariate: Y Wasserstein</th>\n",
       "      <th>Univariate: T Wasserstein</th>\n",
       "      <th>Multivariate: Wasserstein1 p-value</th>\n",
       "      <th>Multivariate: Wasserstein2 p-value</th>\n",
       "      <th>Multivariate: kNN p-value</th>\n",
       "      <th>Multivariate: Energy p-value</th>\n",
       "      <th>Multivariate: Friedman-Rafsky p-value</th>\n",
       "      <th>ATE</th>\n",
       "      <th>Model Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium</td>\n",
       "      <td>seed_420</td>\n",
       "      <td>0.28183</td>\n",
       "      <td>0.952218</td>\n",
       "      <td>0.241516</td>\n",
       "      <td>0.879783</td>\n",
       "      <td>816.970534</td>\n",
       "      <td>0.015432</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-2324.199307</td>\n",
       "      <td>save/sepsis_model_organized\\medium_seed_420\\mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Architecture      Seed  Univariate: Y KS p-value  Univariate: T KS p-value  \\\n",
       "0       medium  seed_420                   0.28183                  0.952218   \n",
       "\n",
       "   Univariate: Y ES p-value  Univariate: T ES p-value  \\\n",
       "0                  0.241516                  0.879783   \n",
       "\n",
       "   Univariate: Y Wasserstein  Univariate: T Wasserstein  \\\n",
       "0                 816.970534                   0.015432   \n",
       "\n",
       "   Multivariate: Wasserstein1 p-value  Multivariate: Wasserstein2 p-value  \\\n",
       "0                                0.02                               0.152   \n",
       "\n",
       "   Multivariate: kNN p-value  Multivariate: Energy p-value  \\\n",
       "0                      0.117                         0.012   \n",
       "\n",
       "   Multivariate: Friedman-Rafsky p-value          ATE  \\\n",
       "0                                  0.235 -2324.199307   \n",
       "\n",
       "                                          Model Path  \n",
       "0  save/sepsis_model_organized\\medium_seed_420\\mo...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected best model: TarNet\n",
      "Model architecture: medium (3 layers, 128 hidden units)\n"
     ]
    }
   ],
   "source": [
    "# Analyze model performance\n",
    "performance_df = analyze_model_performance(results, saveroot)\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "display(performance_df)\n",
    "\n",
    "# Select best model\n",
    "best_model = select_best_model(results, best_model_selector_dict, criterion=\"medium\")\n",
    "print(f\"\\nSelected best model: {best_model.__class__.__name__}\")\n",
    "print(f\"Model architecture: medium (3 layers, 128 hidden units)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08758707",
   "metadata": {},
   "source": [
    "## 4. Generate Synthetic Training Data\n",
    "\n",
    "Generate synthetic training data with counterfactuals for causal inference experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b555cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating synthetic training data with counterfactuals...\n",
      "\n",
      "Generated synthetic training data:\n",
      "- Samples: 405\n",
      "- Features: 30\n",
      "- Treatment distribution: {0.0: 366, 1.0: 39}\n",
      "\n",
      "Sample of generated data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InfectionSuspected</th>\n",
       "      <th>DiagnosticBlood</th>\n",
       "      <th>DisfuncOrg</th>\n",
       "      <th>SIRSCritTachypnea</th>\n",
       "      <th>Hypotensie</th>\n",
       "      <th>SIRSCritHeartRate</th>\n",
       "      <th>Infusion</th>\n",
       "      <th>DiagnosticArtAstrup</th>\n",
       "      <th>Age</th>\n",
       "      <th>DiagnosticIC</th>\n",
       "      <th>...</th>\n",
       "      <th>LacticAcid</th>\n",
       "      <th>Leucocytes_2</th>\n",
       "      <th>CRP_2</th>\n",
       "      <th>LacticAcid_2</th>\n",
       "      <th>LacticAcid_3</th>\n",
       "      <th>t</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y</th>\n",
       "      <th>ite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13062.310547</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>13062.310547</td>\n",
       "      <td>-12763.310547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14308.323242</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>14308.323242</td>\n",
       "      <td>-14009.323242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1438.318848</td>\n",
       "      <td>684.349976</td>\n",
       "      <td>1438.318848</td>\n",
       "      <td>-753.968872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15942.497070</td>\n",
       "      <td>1923.374390</td>\n",
       "      <td>15942.497070</td>\n",
       "      <td>-14019.123047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4340.021484</td>\n",
       "      <td>4846.141602</td>\n",
       "      <td>4340.021484</td>\n",
       "      <td>506.120117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   InfectionSuspected  DiagnosticBlood  DisfuncOrg  SIRSCritTachypnea  \\\n",
       "0                 1.0              1.0         0.0                1.0   \n",
       "1                 1.0              1.0         0.0                1.0   \n",
       "2                 0.0              0.0         0.0                0.0   \n",
       "3                 1.0              1.0         0.0                1.0   \n",
       "4                 1.0              1.0         0.0                1.0   \n",
       "\n",
       "   Hypotensie  SIRSCritHeartRate  Infusion  DiagnosticArtAstrup   Age  \\\n",
       "0         0.0                0.0       1.0                  1.0  90.0   \n",
       "1         0.0                1.0       1.0                  0.0  55.0   \n",
       "2         0.0                0.0       0.0                  0.0  70.0   \n",
       "3         0.0                0.0       1.0                  1.0  90.0   \n",
       "4         0.0                0.0       1.0                  0.0  80.0   \n",
       "\n",
       "   DiagnosticIC  ...  LacticAcid  Leucocytes_2  CRP_2  LacticAcid_2  \\\n",
       "0           1.0  ...         2.4          -1.0   -1.0          -1.0   \n",
       "1           1.0  ...         1.3          -1.0   -1.0          -1.0   \n",
       "2           0.0  ...        -1.0          -1.0   -1.0          -1.0   \n",
       "3           1.0  ...         3.2          -1.0   -1.0          -1.0   \n",
       "4           1.0  ...         3.8          -1.0   -1.0          -1.0   \n",
       "\n",
       "   LacticAcid_3    t            y0           y1             y           ite  \n",
       "0          -1.0  0.0  13062.310547   299.000000  13062.310547 -12763.310547  \n",
       "1          -1.0  0.0  14308.323242   299.000000  14308.323242 -14009.323242  \n",
       "2          -1.0  0.0   1438.318848   684.349976   1438.318848   -753.968872  \n",
       "3          -1.0  0.0  15942.497070  1923.374390  15942.497070 -14019.123047  \n",
       "4          -1.0  0.0   4340.021484  4846.141602   4340.021484    506.120117  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ITE statistics:\n",
      "- Mean ITE: -1987.729980\n",
      "- Std ITE: 7365.526367\n",
      "- ATE: -1987.729980\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic training data\n",
    "print(\"Generating synthetic training data with counterfactuals...\")\n",
    "\n",
    "w_train, t_train, y0, y1 = generate_synthetic_data(\n",
    "    best_model, seed=EXPERIMENT_SEED, dataset='train'\n",
    ")\n",
    "\n",
    "# Create formatted dataframe\n",
    "w_samples_df = create_dataframe_from_synthetic_data(\n",
    "    w_train, t_train, y0, y1, w_cols\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated synthetic training data:\")\n",
    "print(f\"- Samples: {len(w_samples_df)}\")\n",
    "print(f\"- Features: {len([col for col in w_samples_df.columns if col in w_cols])}\")\n",
    "print(f\"- Treatment distribution: {dict(w_samples_df['t'].value_counts())}\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample of generated data:\")\n",
    "display(w_samples_df.head())\n",
    "\n",
    "print(f\"\\nITE statistics:\")\n",
    "print(f\"- Mean ITE: {w_samples_df['ite'].mean():.6f}\")\n",
    "print(f\"- Std ITE: {w_samples_df['ite'].std():.6f}\")\n",
    "print(f\"- ATE: {w_samples_df['ite'].mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dccc73",
   "metadata": {},
   "source": [
    "## 5. Variant Assignment and Data Preparation\n",
    "\n",
    "Assign data to variants based on feature patterns and prepare datasets for causal modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eecdc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning variants based on feature patterns...\n",
      "\n",
      "Found 10 unique feature patterns\n",
      "Top 10 patterns:\n",
      "   1. Pattern 111111111111111111111111110000: 336 cases (82.96%)\n",
      "   2. Pattern 111111111111111111111111100000: 32 cases (7.90%)\n",
      "   3. Pattern 111111111111111111111111010000: 15 cases (3.70%)\n",
      "   4. Pattern 111111111111111111111111000000: 7 cases (1.73%)\n",
      "   5. Pattern 111111111111111111111111111100: 5 cases (1.23%)\n",
      "   6. Pattern 111111111111111111111111111000: 4 cases (0.99%)\n",
      "   7. Pattern 111111111111111111111110000000: 3 cases (0.74%)\n",
      "   8. Pattern 111111111111111111111111110010: 1 cases (0.25%)\n",
      "   9. Pattern 111111111111111111111110100000: 1 cases (0.25%)\n",
      "  10. Pattern 111111111111111111111111110110: 1 cases (0.25%)\n",
      "\n",
      "Using top 2 patterns as specific variants:\n",
      "  Variant 1: 111111111111111111111111110000 (336 cases, 82.96%)\n",
      "  Variant 2: 111111111111111111111111100000 (32 cases, 7.90%)\n",
      "  Variant 3: All other patterns (remaining cases)\n",
      "['InfectionSuspected', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'Age', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG', 'Leucocytes', 'CRP', 'LacticAcid', 'Leucocytes_2', 'CRP_2', 'LacticAcid_2', 'LacticAcid_3']\n",
      "\n",
      "Final variant distribution:\n",
      "  Variant 1: 336 cases (82.96%)\n",
      "  Variant 2: 32 cases (7.90%)\n",
      "  Variant 3: 37 cases (9.14%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate feature patterns and assign variants\n",
    "print(\"Assigning variants based on feature patterns...\")\n",
    "\n",
    "# Get feature columns\n",
    "feature_cols = [col for col in w_samples_df.columns if col not in ['t', 'y', 'y0', 'y1', 'ite', 'variant', 'feature_pattern']]\n",
    "feature_mask = w_samples_df[feature_cols] >= 0\n",
    "# print(feature_mask)\n",
    "w_samples_df['feature_pattern'] = feature_mask.apply(\n",
    "    lambda row: ''.join(['1' if val else '0' for val in row]), axis=1\n",
    ")\n",
    "\n",
    "# Analyze pattern frequencies\n",
    "pattern_counts = w_samples_df['feature_pattern'].value_counts()\n",
    "print(f\"\\nFound {len(pattern_counts)} unique feature patterns\")\n",
    "print(f\"Top 10 patterns:\")\n",
    "for i, (pattern, count) in enumerate(pattern_counts.head(10).items(), 1):\n",
    "    print(f\"  {i:2d}. Pattern {pattern}: {count} cases ({count/len(w_samples_df)*100:.2f}%)\")\n",
    "\n",
    "# Get top variants for assignment\n",
    "k = NUM_VARIANTS\n",
    "top_variants = pattern_counts.index[:k-1]  # Top k-1 patterns\n",
    "\n",
    "print(f\"\\nUsing top {k-1} patterns as specific variants:\")\n",
    "for i, pattern in enumerate(top_variants, 1):\n",
    "    count = pattern_counts[pattern]\n",
    "    print(f\"  Variant {i}: {pattern} ({count} cases, {count/len(w_samples_df)*100:.2f}%)\")\n",
    "print(f\"  Variant {k}: All other patterns (remaining cases)\")\n",
    "\n",
    "\n",
    "# Assign variants using the patterns\n",
    "w_samples_df = assign_variants_by_patterns(w_samples_df.drop(columns=['feature_pattern']), top_variants, k)\n",
    "\n",
    "# Display variant distribution\n",
    "variant_counts = w_samples_df['variant'].value_counts().sort_index()\n",
    "print(f\"\\nFinal variant distribution:\")\n",
    "for variant, count in variant_counts.items():\n",
    "    print(f\"  Variant {variant}: {count} cases ({count/len(w_samples_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d703d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating variant-specific dataframes...\n",
      "\n",
      "Created 3 variant-specific datasets:\n",
      "  Variant 1:\n",
      "    - Cases: 336 (83.0%)\n",
      "    - Features: 26\n",
      "    - Pattern: 111111111111111111111111110000\n",
      "    - Columns: ['t', 'y', 'y0', 'y1', 'ite', 'InfectionSuspected', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'Age', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG', 'Leucocytes', 'CRP', 'LacticAcid']\n",
      "  Variant 2:\n",
      "    - Cases: 32 (7.9%)\n",
      "    - Features: 25\n",
      "    - Pattern: 111111111111111111111111100000\n",
      "    - Columns: ['t', 'y', 'y0', 'y1', 'ite', 'InfectionSuspected', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'Age', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG', 'Leucocytes', 'CRP']\n",
      "  Variant 3:\n",
      "    - Cases: 37 (9.1%)\n",
      "    - Features: 30\n",
      "    - Pattern: 111111111111111111111111010000\n",
      "    - Columns: ['t', 'y', 'y0', 'y1', 'ite', 'InfectionSuspected', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'Age', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG', 'Leucocytes', 'CRP', 'LacticAcid', 'Leucocytes_2', 'CRP_2', 'LacticAcid_2', 'LacticAcid_3']\n",
      "\n",
      "Variant Information Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>count</th>\n",
       "      <th>percent</th>\n",
       "      <th>pattern</th>\n",
       "      <th>num_features</th>\n",
       "      <th>feature_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>336</td>\n",
       "      <td>82.962963</td>\n",
       "      <td>111111111111111111111111110000</td>\n",
       "      <td>26</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>7.901235</td>\n",
       "      <td>111111111111111111111111100000</td>\n",
       "      <td>25</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>9.135802</td>\n",
       "      <td>111111111111111111111111010000</td>\n",
       "      <td>30</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>9.135802</td>\n",
       "      <td>111111111111111111111111111100</td>\n",
       "      <td>30</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>9.135802</td>\n",
       "      <td>111111111111111111111111111000</td>\n",
       "      <td>30</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>9.135802</td>\n",
       "      <td>111111111111111111111111110010</td>\n",
       "      <td>30</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>9.135802</td>\n",
       "      <td>111111111111111111111110000000</td>\n",
       "      <td>30</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>9.135802</td>\n",
       "      <td>111111111111111111111111000000</td>\n",
       "      <td>30</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>9.135802</td>\n",
       "      <td>111111111111111111111110100000</td>\n",
       "      <td>30</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>9.135802</td>\n",
       "      <td>111111111111111111111111110110</td>\n",
       "      <td>30</td>\n",
       "      <td>[InfectionSuspected, DiagnosticBlood, DisfuncO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variant  count    percent                         pattern  num_features  \\\n",
       "0        1    336  82.962963  111111111111111111111111110000            26   \n",
       "1        2     32   7.901235  111111111111111111111111100000            25   \n",
       "2        3     37   9.135802  111111111111111111111111010000            30   \n",
       "3        3     37   9.135802  111111111111111111111111111100            30   \n",
       "4        3     37   9.135802  111111111111111111111111111000            30   \n",
       "5        3     37   9.135802  111111111111111111111111110010            30   \n",
       "6        3     37   9.135802  111111111111111111111110000000            30   \n",
       "7        3     37   9.135802  111111111111111111111111000000            30   \n",
       "8        3     37   9.135802  111111111111111111111110100000            30   \n",
       "9        3     37   9.135802  111111111111111111111111110110            30   \n",
       "\n",
       "                                     feature_columns  \n",
       "0  [InfectionSuspected, DiagnosticBlood, DisfuncO...  \n",
       "1  [InfectionSuspected, DiagnosticBlood, DisfuncO...  \n",
       "2  [InfectionSuspected, DiagnosticBlood, DisfuncO...  \n",
       "3  [InfectionSuspected, DiagnosticBlood, DisfuncO...  \n",
       "4  [InfectionSuspected, DiagnosticBlood, DisfuncO...  \n",
       "5  [InfectionSuspected, DiagnosticBlood, DisfuncO...  \n",
       "6  [InfectionSuspected, DiagnosticBlood, DisfuncO...  \n",
       "7  [InfectionSuspected, DiagnosticBlood, DisfuncO...  \n",
       "8  [InfectionSuspected, DiagnosticBlood, DisfuncO...  \n",
       "9  [InfectionSuspected, DiagnosticBlood, DisfuncO...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create variant-specific dataframes\n",
    "print(\"Creating variant-specific dataframes...\")\n",
    "\n",
    "variant_dataframes, variant_info = group_by_variants_with_filtered_columns(\n",
    "    w_samples_df, num_variants=k\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated {len(variant_dataframes)} variant-specific datasets:\")\n",
    "for variant_num in sorted(variant_dataframes.keys()):\n",
    "    df = variant_dataframes[variant_num]\n",
    "    info = variant_info[variant_info['variant'] == variant_num].iloc[0]\n",
    "    print(f\"  Variant {variant_num}:\")\n",
    "    print(f\"    - Cases: {len(df)} ({info['percent']:.1f}%)\")\n",
    "    print(f\"    - Features: {info['num_features']}\")\n",
    "    print(f\"    - Pattern: {info['pattern']}\")\n",
    "    print(f\"    - Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Display variant info table\n",
    "print(\"\\nVariant Information Summary:\")\n",
    "display(variant_info[['variant', 'count', 'percent', 'pattern', 'num_features', 'feature_columns']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff01af3",
   "metadata": {},
   "source": [
    "## 6. Prepare Test and Validation Data\n",
    "\n",
    "Extract test and validation datasets from the trained model and process them using the same variant patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61e9457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting test data from the trained model...\n",
      "Test data prepared:\n",
      "- Shape: (324, 35)\n",
      "- Treatment distribution: {0.0: 297, 1.0: 27}\n",
      "\n",
      "Training variant patterns for consistent assignment:\n",
      "  Variant 1: 111111111111111111111111110000\n",
      "  Variant 2: 111111111111111111111111100000\n"
     ]
    }
   ],
   "source": [
    "# Extract test data from the best model\n",
    "print(\"Extracting test data from the trained model...\")\n",
    "\n",
    "w_test, t_test, y_test = best_model.get_data(dataset='test')\n",
    "y_test_counterfactual = best_model.sample_y(\n",
    "    t=1-t_test, w=w_test, ret_counterfactuals=False, seed=INITIAL_SEED\n",
    ")\n",
    "\n",
    "# Create test dataframe\n",
    "if w_test.shape[1] == len(w_cols):\n",
    "    w_test_df = pd.DataFrame(w_test, columns=w_cols)\n",
    "else:\n",
    "    column_names = [f\"feature_{i}\" for i in range(w_test.shape[1])]\n",
    "    w_test_df = pd.DataFrame(w_test, columns=column_names)\n",
    "\n",
    "w_test_df['t'] = t_test\n",
    "w_test_df['y'] = y_test\n",
    "w_test_df['y0'] = np.where(t_test.flatten() == 0, y_test.flatten(), y_test_counterfactual.flatten())\n",
    "w_test_df['y1'] = np.where(t_test.flatten() == 1, y_test.flatten(), y_test_counterfactual.flatten())\n",
    "w_test_df['ite'] = w_test_df['y1'] - w_test_df['y0']\n",
    "\n",
    "print(f\"Test data prepared:\")\n",
    "print(f\"- Shape: {w_test_df.shape}\")\n",
    "print(f\"- Treatment distribution: {dict(w_test_df['t'].value_counts())}\")\n",
    "\n",
    "# Extract training variant patterns for consistent assignment\n",
    "training_variant_patterns = {}\n",
    "for variant_num in sorted(list(variant_dataframes.keys())[:-1]):  # Exclude last variant\n",
    "    training_pattern = variant_info[variant_info['variant'] == variant_num]['pattern'].iloc[0]\n",
    "    training_variant_patterns[variant_num] = training_pattern\n",
    "\n",
    "print(f\"\\nTraining variant patterns for consistent assignment:\")\n",
    "for variant_num, pattern in training_variant_patterns.items():\n",
    "    print(f\"  Variant {variant_num}: {pattern}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9edff618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data with training variant patterns...\n",
      "\n",
      "Processed test data into 3 variant-specific datasets:\n",
      "  Test Variant 1: 258 samples\n",
      "  Test Variant 2: 33 samples\n",
      "  Test Variant 3: 33 samples\n",
      "\n",
      "Created 3 global test datasets for global model evaluation.\n"
     ]
    }
   ],
   "source": [
    "# Process test data using training patterns\n",
    "print(\"Processing test data with training variant patterns...\")\n",
    "\n",
    "test_variant_dataframes, test_variant_info = process_test_data_with_training_variants(\n",
    "    w_test_df, training_variant_patterns, num_variants=k\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed test data into {len(test_variant_dataframes)} variant-specific datasets:\")\n",
    "for variant_num in sorted(test_variant_dataframes.keys()):\n",
    "    df = test_variant_dataframes[variant_num]\n",
    "    print(f\"  Test Variant {variant_num}: {len(df)} samples\")\n",
    "\n",
    "# Also create global test variant dataframes\n",
    "global_test_variant_dataframes, global_test_variant_info = process_test_data_with_training_variants(\n",
    "    w_test_df, training_variant_patterns, num_variants=len(training_variant_patterns)+1, for_global_model=True\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated {len(global_test_variant_dataframes)} global test datasets for global model evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8b977c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing validation dataset...\n",
      "Validation data prepared:\n",
      "- Shape: (81, 35)\n",
      "- Treatment distribution: {0.0: 72, 1.0: 9}\n",
      "- Variant-specific datasets: 3\n",
      "- Global validation datasets: 3\n",
      "\n",
      "Validation set sizes by variant:\n",
      "  Variant 1: 67 samples\n",
      "  Variant 2: 7 samples\n",
      "  Variant 3: 7 samples\n",
      "\n",
      "Data preparation completed!\n",
      "Ready for causal inference experiments.\n"
     ]
    }
   ],
   "source": [
    "# Extract and process validation data\n",
    "print(\"Preparing validation dataset...\")\n",
    "\n",
    "w_val, t_val, y_val = best_model.get_data(dataset='val')\n",
    "y_val_counterfactual = best_model.sample_y(\n",
    "    t=1-t_val, w=w_val, ret_counterfactuals=False, seed=INITIAL_SEED\n",
    ")\n",
    "\n",
    "# Create validation dataframe\n",
    "if w_val.shape[1] == len(w_cols):\n",
    "    w_val_df = pd.DataFrame(w_val, columns=w_cols)\n",
    "else:\n",
    "    column_names = [f\"feature_{i}\" for i in range(w_val.shape[1])]\n",
    "    w_val_df = pd.DataFrame(w_val, columns=column_names)\n",
    "\n",
    "w_val_df['t'] = t_val\n",
    "w_val_df['y'] = y_val\n",
    "w_val_df['y0'] = np.where(t_val.flatten() == 0, y_val.flatten(), y_val_counterfactual.flatten())\n",
    "w_val_df['y1'] = np.where(t_val.flatten() == 1, y_val.flatten(), y_val_counterfactual.flatten())\n",
    "w_val_df['ite'] = w_val_df['y1'] - w_val_df['y0']\n",
    "\n",
    "# Process validation data into variants\n",
    "val_variant_dataframes, val_variant_info = process_test_data_with_training_variants(\n",
    "    w_val_df, training_variant_patterns, num_variants=k\n",
    ")\n",
    "\n",
    "global_val_variant_dataframes, global_val_variant_info = process_test_data_with_training_variants(\n",
    "    w_val_df, training_variant_patterns, num_variants=len(training_variant_patterns)+1, for_global_model=True\n",
    ")\n",
    "\n",
    "print(f\"Validation data prepared:\")\n",
    "print(f\"- Shape: {w_val_df.shape}\")\n",
    "print(f\"- Treatment distribution: {dict(w_val_df['t'].value_counts())}\")\n",
    "print(f\"- Variant-specific datasets: {len(val_variant_dataframes)}\")\n",
    "print(f\"- Global validation datasets: {len(global_val_variant_dataframes)}\")\n",
    "\n",
    "print(\"\\nValidation set sizes by variant:\")\n",
    "for variant_num in sorted(val_variant_dataframes.keys()):\n",
    "    print(f\"  Variant {variant_num}: {len(val_variant_dataframes[variant_num])} samples\")\n",
    "\n",
    "print(\"\\nData preparation completed!\")\n",
    "print(\"Ready for causal inference experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0312989",
   "metadata": {},
   "source": [
    "## 7. Multi-Seed Causal Inference Experiments\n",
    "\n",
    "Run comprehensive causal inference experiments across multiple random seeds to assess the robustness of both global and variant-specific modeling approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc38f7b",
   "metadata": {},
   "source": [
    "### 7.1 Experiment Configuration\n",
    "\n",
    "Configure the multi-seed experiment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ae39e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Seed Experiment Configuration:\n",
      "==================================================\n",
      "Experiment seeds: [0, 1]\n",
      "Number of seeds: 2\n",
      "R² threshold for model selection: 0.1\n",
      "Number of variants: 3\n",
      "Results save path: C:\\Users\\Guy\\OneDrive\\Shared Documents\\Technion\\Msc\\process_mining_BP_CDM\\thesis\\code\\realcause-for-cpvs\\cdv_experiments_results_example.pkl\n",
      "\n",
      "Experiment will compare:\n",
      "1. Global Method: Single model trained on all data\n",
      "2. Variant Method: Separate models per variant (with global fallback)\n",
      "\n",
      "For each method, we will evaluate:\n",
      "- All estimator types (S-Learner, T-Learner, X-Learner, DR-Learner, Double-ML)\n",
      "- Best estimator selection based on validation performance\n",
      "\n",
      "Ready to start experiment...\n"
     ]
    }
   ],
   "source": [
    "# Configure multi-seed experiment\n",
    "experiment_seeds = [0, 1]  # Can expand to more seeds. In our paper: list(range(0, 500))\n",
    "results_save_path = \"C:\\\\Users\\\\Guy\\\\OneDrive\\\\Shared Documents\\\\Technion\\\\Msc\\\\process_mining_BP_CDM\\\\thesis\\\\code\\\\realcause-for-cpvs\\\\cdv_experiments_results_example.pkl\"\n",
    "\n",
    "print(\"Multi-Seed Experiment Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Experiment seeds: {experiment_seeds}\")\n",
    "print(f\"Number of seeds: {len(experiment_seeds)}\")\n",
    "print(f\"R² threshold for model selection: {R2_THRESHOLD}\")\n",
    "print(f\"Number of variants: {NUM_VARIANTS}\")\n",
    "print(f\"Results save path: {results_save_path}\")\n",
    "\n",
    "print(f\"\\nExperiment will compare:\")\n",
    "print(f\"1. Global Method: Single model trained on all data\")\n",
    "print(f\"2. Variant Method: Separate models per variant (with global fallback)\")\n",
    "\n",
    "print(f\"\\nFor each method, we will evaluate:\")\n",
    "print(f\"- All estimator types (S-Learner, T-Learner, X-Learner, DR-Learner, Double-ML)\")\n",
    "print(f\"- Best estimator selection based on validation performance\")\n",
    "\n",
    "print(f\"\\nReady to start experiment...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00883d31",
   "metadata": {},
   "source": [
    "### 7.2 Run Multi-Seed Experiment\n",
    "\n",
    "Execute the main experiment loop across all seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4785c3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Multi-Seed Causal Inference Experiment...\n",
      "This may take several minutes depending on the number of seeds and data size.\n",
      "\n",
      "======================================================================\n",
      "======================================================================\n",
      "Starting Multi-Seed Experiment with 2 seeds\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing seeds:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SEED 0 (1/2)\n",
      "======================================================================\n",
      "[0] Step 1/5: Generating training data...\n",
      "['InfectionSuspected', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'Age', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG', 'Leucocytes', 'CRP', 'LacticAcid', 'Leucocytes_2', 'CRP_2', 'LacticAcid_2', 'LacticAcid_3']\n",
      "[0] Step 2/5: Initializing estimators...\n",
      "[0] Step 3/5: Training models and generating predictions...\n",
      "[0] Step 4/5: Predicting on validation data for best model selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing seeds:  50%|█████     | 1/2 [00:13<00:13, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Selecting best global model...\n",
      "[0] Selecting best models per variant...\n",
      "[0] Step 5/5: Creating result dataframes with best models...\n",
      "[0] ✓ Completed. Results saved to C:\\Users\\Guy\\OneDrive\\Shared Documents\\Technion\\Msc\\process_mining_BP_CDM\\thesis\\code\\realcause-for-cpvs\\cdv_experiments_results_example.pkl\n",
      "\n",
      "======================================================================\n",
      "SEED 1 (2/2)\n",
      "======================================================================\n",
      "[1] Step 1/5: Generating training data...\n",
      "['InfectionSuspected', 'DiagnosticBlood', 'DisfuncOrg', 'SIRSCritTachypnea', 'Hypotensie', 'SIRSCritHeartRate', 'Infusion', 'DiagnosticArtAstrup', 'Age', 'DiagnosticIC', 'DiagnosticSputum', 'DiagnosticLiquor', 'DiagnosticOther', 'SIRSCriteria2OrMore', 'DiagnosticXthorax', 'SIRSCritTemperature', 'DiagnosticUrinaryCulture', 'SIRSCritLeucos', 'Oligurie', 'DiagnosticLacticAcid', 'Hypoxie', 'DiagnosticUrinarySediment', 'DiagnosticECG', 'Leucocytes', 'CRP', 'LacticAcid', 'Leucocytes_2', 'CRP_2', 'LacticAcid_2', 'LacticAcid_3']\n",
      "[1] Step 2/5: Initializing estimators...\n",
      "[1] Step 3/5: Training models and generating predictions...\n",
      "[1] Step 4/5: Predicting on validation data for best model selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing seeds: 100%|██████████| 2/2 [00:27<00:00, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Selecting best global model...\n",
      "[1] Selecting best models per variant...\n",
      "[1] Step 5/5: Creating result dataframes with best models...\n",
      "[1] ✓ Completed. Results saved to C:\\Users\\Guy\\OneDrive\\Shared Documents\\Technion\\Msc\\process_mining_BP_CDM\\thesis\\code\\realcause-for-cpvs\\cdv_experiments_results_example.pkl\n",
      "\n",
      "======================================================================\n",
      "Multi-Seed Experiment Complete!\n",
      "======================================================================\n",
      "Total seeds processed: 2\n",
      "Results saved to: C:\\Users\\Guy\\OneDrive\\Shared Documents\\Technion\\Msc\\process_mining_BP_CDM\\thesis\\code\\realcause-for-cpvs\\cdv_experiments_results_example.pkl\n",
      "\n",
      "======================================================================\n",
      "Multi-Seed Experiment COMPLETED Successfully!\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Force reload modules to get the updated tqdm imports\n",
    "import importlib\n",
    "import cdv_utils.experiment_runner\n",
    "importlib.reload(cdv_utils.experiment_runner)\n",
    "from cdv_utils.experiment_runner import run_multi_seed_experiment\n",
    "\n",
    "# Run the multi-seed experiment\n",
    "print(\"Starting Multi-Seed Causal Inference Experiment...\")\n",
    "print(\"This may take several minutes depending on the number of seeds and data size.\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "try:\n",
    "    results_by_seed = run_multi_seed_experiment(\n",
    "        best_model=best_model,\n",
    "        experiment_seeds=experiment_seeds,\n",
    "        w_cols=w_cols,\n",
    "        top_variants=top_variants,\n",
    "        k=k,\n",
    "        training_variant_patterns=training_variant_patterns,\n",
    "        test_variant_dataframes=test_variant_dataframes,\n",
    "        val_variant_dataframes=val_variant_dataframes,\n",
    "        global_test_variant_dataframes=global_test_variant_dataframes,\n",
    "        global_val_variant_dataframes=global_val_variant_dataframes,\n",
    "        results_save_path=results_save_path,\n",
    "        initial_seed=INITIAL_SEED,\n",
    "        r2_threshold=R2_THRESHOLD\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"Multi-Seed Experiment COMPLETED Successfully!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Experiment failed with error: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    # Try to load partial results\n",
    "    try:\n",
    "        from cdv_utils.experiment_runner import load_experiment_results\n",
    "        results_by_seed = load_experiment_results(results_save_path)\n",
    "        if results_by_seed:\n",
    "            print(f\"\\n✅ Loaded {len(results_by_seed)} partial results from {results_save_path}\")\n",
    "        else:\n",
    "            print(f\"\\n❌ No partial results found.\")\n",
    "            results_by_seed = {}\n",
    "    except:\n",
    "        results_by_seed = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0877867a",
   "metadata": {},
   "source": [
    "### 7.3 Analyze Experiment Results\n",
    "\n",
    "Analyze and summarize the results from the multi-seed experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b479d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Multi-Seed Experiment Results...\n",
      "==================================================\n",
      "\n",
      "Experiment Summary:\n",
      "- Total seeds attempted: 2\n",
      "- Successfully completed: 2\n",
      "- Failed: 0\n",
      "- Success rate: 100.0%\n",
      "\n",
      "Successful seeds: [0, 1]\n",
      "\n",
      "Detailed Results by Seed:\n",
      "\n",
      "  Seed 0:\n",
      "    - Global method (all estimators): (1944, 11)\n",
      "    - Global method (best): (324, 11)\n",
      "    - Variant method (all estimators): (1944, 12)\n",
      "    - Variant method (best): (324, 12)\n",
      "    - Best global model: S-Learner (Linear) (R²: -0.0140, ATE bias: 1422.668820)\n",
      "    - Best models selected for 3 variants\n",
      "\n",
      "  Seed 1:\n",
      "    - Global method (all estimators): (1944, 11)\n",
      "    - Global method (best): (324, 11)\n",
      "    - Variant method (all estimators): (1944, 12)\n",
      "    - Variant method (best): (324, 12)\n",
      "    - Best global model: S-Learner (Linear) (R²: -0.0002, ATE bias: 150.766137)\n",
      "    - Best models selected for 3 variants\n"
     ]
    }
   ],
   "source": [
    "# Analyze experiment results\n",
    "if results_by_seed:\n",
    "    print(\"Analyzing Multi-Seed Experiment Results...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get analysis summary\n",
    "    analysis = analyze_experiment_results(results_by_seed)\n",
    "    \n",
    "    print(f\"\\nExperiment Summary:\")\n",
    "    print(f\"- Total seeds attempted: {analysis['total_seeds']}\")\n",
    "    print(f\"- Successfully completed: {len(analysis['successful_seeds'])}\")\n",
    "    print(f\"- Failed: {len(analysis['failed_seeds'])}\")\n",
    "    \n",
    "    if analysis['successful_seeds']:\n",
    "        print(f\"- Success rate: {len(analysis['successful_seeds'])/analysis['total_seeds']*100:.1f}%\")\n",
    "        \n",
    "        print(f\"\\nSuccessful seeds: {analysis['successful_seeds']}\")\n",
    "        if analysis['failed_seeds']:\n",
    "            print(f\"Failed seeds: {analysis['failed_seeds']}\")\n",
    "        \n",
    "        # Show detailed results for each successful seed\n",
    "        print(f\"\\nDetailed Results by Seed:\")\n",
    "        for seed in analysis['successful_seeds']:\n",
    "            summary = analysis['summary_by_seed'][seed]\n",
    "            print(f\"\\n  Seed {seed}:\")\n",
    "            print(f\"    - Global method (all estimators): {summary['global_method_shape']}\")\n",
    "            print(f\"    - Global method (best): {summary['global_method_best_shape']}\")\n",
    "            print(f\"    - Variant method (all estimators): {summary['variant_method_shape']}\")\n",
    "            print(f\"    - Variant method (best): {summary['variant_method_best_shape']}\")\n",
    "            \n",
    "            if summary['best_global_model']:\n",
    "                bgm = summary['best_global_model']\n",
    "                print(f\"    - Best global model: {bgm['estimator']} (R²: {bgm['r2']:.4f}, ATE bias: {bgm['ate_bias']:.6f})\")\n",
    "            \n",
    "            print(f\"    - Best models selected for {summary['best_models_count']} variants\")\n",
    "    else:\n",
    "        print(\"\\n❌ No successful experiments to analyze.\")\n",
    "        print(\"Please check the error messages above and retry with different parameters.\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ No experiment results available to analyze.\")\n",
    "    print(\"The experiment may have failed or no results were saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13948a15",
   "metadata": {},
   "source": [
    "### 7.4 Results Summary and Export\n",
    "\n",
    "Provide final summary and export key results for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a7266d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results Summary\n",
      "==================================================\n",
      "\n",
      "Results Structure (example from seed 0):\n",
      "\n",
      "1. Global Method (All Estimators):\n",
      "   - Shape: (1944, 11)\n",
      "   - Variants: [1, 2, 3]\n",
      "   - Estimators: ['DR Learner (EconML)', 'Double ML', 'S-Learner (Linear)', 'S-Learner (RF)', 'T-Learner (RF)', 'X-Learner (RF)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>estimator</th>\n",
       "      <th>method</th>\n",
       "      <th>t</th>\n",
       "      <th>y</th>\n",
       "      <th>y0_real</th>\n",
       "      <th>y1_real</th>\n",
       "      <th>y0_pred</th>\n",
       "      <th>y1_pred</th>\n",
       "      <th>ite_real</th>\n",
       "      <th>ite_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S-Learner (Linear)</td>\n",
       "      <td>global</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10886.0</td>\n",
       "      <td>10886.0</td>\n",
       "      <td>45481.902344</td>\n",
       "      <td>7787.081335</td>\n",
       "      <td>5791.162805</td>\n",
       "      <td>34595.902344</td>\n",
       "      <td>-1995.91853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S-Learner (Linear)</td>\n",
       "      <td>global</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4477.0</td>\n",
       "      <td>4477.0</td>\n",
       "      <td>6704.216797</td>\n",
       "      <td>7787.081335</td>\n",
       "      <td>5791.162805</td>\n",
       "      <td>2227.216797</td>\n",
       "      <td>-1995.91853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>S-Learner (Linear)</td>\n",
       "      <td>global</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14947.0</td>\n",
       "      <td>14947.0</td>\n",
       "      <td>2850.990479</td>\n",
       "      <td>7787.081335</td>\n",
       "      <td>5791.162805</td>\n",
       "      <td>-12096.009521</td>\n",
       "      <td>-1995.91853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variant           estimator  method    t        y  y0_real       y1_real  \\\n",
       "0        1  S-Learner (Linear)  global  0.0  10886.0  10886.0  45481.902344   \n",
       "1        1  S-Learner (Linear)  global  0.0   4477.0   4477.0   6704.216797   \n",
       "2        1  S-Learner (Linear)  global  0.0  14947.0  14947.0   2850.990479   \n",
       "\n",
       "       y0_pred      y1_pred      ite_real    ite_pred  \n",
       "0  7787.081335  5791.162805  34595.902344 -1995.91853  \n",
       "1  7787.081335  5791.162805   2227.216797 -1995.91853  \n",
       "2  7787.081335  5791.162805 -12096.009521 -1995.91853  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Variant Method (Best Estimators):\n",
      "   - Shape: (324, 12)\n",
      "   - Variants: [1, 2, 3]\n",
      "   - Estimators: ['S-Learner (Linear)', 'best_global_model']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variant</th>\n",
       "      <th>estimator</th>\n",
       "      <th>method</th>\n",
       "      <th>used_global_model</th>\n",
       "      <th>t</th>\n",
       "      <th>y</th>\n",
       "      <th>y0_real</th>\n",
       "      <th>y1_real</th>\n",
       "      <th>y0_pred</th>\n",
       "      <th>y1_pred</th>\n",
       "      <th>ite_real</th>\n",
       "      <th>ite_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S-Learner (Linear)</td>\n",
       "      <td>variant</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10886.0</td>\n",
       "      <td>10886.0</td>\n",
       "      <td>45481.902344</td>\n",
       "      <td>7448.014388</td>\n",
       "      <td>6081.399674</td>\n",
       "      <td>34595.902344</td>\n",
       "      <td>-1366.614714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>S-Learner (Linear)</td>\n",
       "      <td>variant</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4477.0</td>\n",
       "      <td>4477.0</td>\n",
       "      <td>6704.216797</td>\n",
       "      <td>7448.014388</td>\n",
       "      <td>6081.399674</td>\n",
       "      <td>2227.216797</td>\n",
       "      <td>-1366.614714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>S-Learner (Linear)</td>\n",
       "      <td>variant</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14947.0</td>\n",
       "      <td>14947.0</td>\n",
       "      <td>2850.990479</td>\n",
       "      <td>7448.014388</td>\n",
       "      <td>6081.399674</td>\n",
       "      <td>-12096.009521</td>\n",
       "      <td>-1366.614714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variant           estimator   method  used_global_model    t        y  \\\n",
       "0        1  S-Learner (Linear)  variant              False  0.0  10886.0   \n",
       "1        1  S-Learner (Linear)  variant              False  0.0   4477.0   \n",
       "2        1  S-Learner (Linear)  variant              False  0.0  14947.0   \n",
       "\n",
       "   y0_real       y1_real      y0_pred      y1_pred      ite_real     ite_pred  \n",
       "0  10886.0  45481.902344  7448.014388  6081.399674  34595.902344 -1366.614714  \n",
       "1   4477.0   6704.216797  7448.014388  6081.399674   2227.216797 -1366.614714  \n",
       "2  14947.0   2850.990479  7448.014388  6081.399674 -12096.009521 -1366.614714  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Summary exported to: results/experiment_summary.json\n",
      "\n",
      "✅ Complete results saved to: C:\\Users\\Guy\\OneDrive\\Shared Documents\\Technion\\Msc\\process_mining_BP_CDM\\thesis\\code\\realcause-for-cpvs\\cdv_experiments_results_example.pkl\n",
      "\n",
      "To load results in future sessions:\n",
      "```python\n",
      "from cdv_utils.experiment_runner import load_experiment_results\n",
      "results = load_experiment_results('C:\\Users\\Guy\\OneDrive\\Shared Documents\\Technion\\Msc\\process_mining_BP_CDM\\thesis\\code\\realcause-for-cpvs\\cdv_experiments_results_example.pkl')\n",
      "```\n",
      "\n",
      "======================================================================\n",
      "CDV Modeling Notebook Execution Complete!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final results summary\n",
    "if results_by_seed and len(results_by_seed) > 0:\n",
    "    print(\"Final Results Summary\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Get a sample of results to show structure\n",
    "    first_seed = list(results_by_seed.keys())[0]\n",
    "    sample_results = results_by_seed[first_seed]\n",
    "    \n",
    "    print(f\"\\nResults Structure (example from seed {first_seed}):\")\n",
    "    print(f\"\\n1. Global Method (All Estimators):\")\n",
    "    if not sample_results['global_method'].empty:\n",
    "        gm_df = sample_results['global_method']\n",
    "        print(f\"   - Shape: {gm_df.shape}\")\n",
    "        print(f\"   - Variants: {sorted(gm_df['variant'].unique())}\")\n",
    "        print(f\"   - Estimators: {sorted(gm_df['estimator'].unique())}\")\n",
    "        display(gm_df.head(3))\n",
    "    \n",
    "    print(f\"\\n2. Variant Method (Best Estimators):\")\n",
    "    if not sample_results['variant_method_best'].empty:\n",
    "        vmb_df = sample_results['variant_method_best']\n",
    "        print(f\"   - Shape: {vmb_df.shape}\")\n",
    "        print(f\"   - Variants: {sorted(vmb_df['variant'].unique())}\")\n",
    "        print(f\"   - Estimators: {sorted(vmb_df['estimator'].unique())}\")\n",
    "        display(vmb_df.head(3))\n",
    "    \n",
    "    # Export summary statistics\n",
    "    export_path = \"results/experiment_summary.json\"\n",
    "    \n",
    "    try:\n",
    "        # Create exportable summary\n",
    "        export_summary = {\n",
    "            'experiment_config': {\n",
    "                'seeds': experiment_seeds,\n",
    "                'num_variants': NUM_VARIANTS,\n",
    "                'r2_threshold': R2_THRESHOLD,\n",
    "                'initial_seed': INITIAL_SEED\n",
    "            },\n",
    "            'results': analysis\n",
    "        }\n",
    "        \n",
    "        with open(export_path, 'w') as f:\n",
    "            json.dump(export_summary, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"\\n✅ Summary exported to: {export_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n⚠️ Could not export summary: {str(e)}\")\n",
    "    \n",
    "    print(f\"\\n✅ Complete results saved to: {results_save_path}\")\n",
    "    print(f\"\\nTo load results in future sessions:\")\n",
    "    print(f\"```python\")\n",
    "    print(f\"from cdv_utils.experiment_runner import load_experiment_results\")\n",
    "    print(f\"results = load_experiment_results('{results_save_path}')\")\n",
    "    print(f\"```\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n❌ No results to summarize.\")\n",
    "    print(\"\\nTo retry the experiment:\")\n",
    "    print(\"1. Check that all data preparation steps completed successfully\")\n",
    "    print(\"2. Verify that the RealCause model was trained properly\")\n",
    "    print(\"3. Consider using fewer seeds or simpler model configurations for initial testing\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CDV Modeling Notebook Execution Complete!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICPM_paper2025_2nd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
